{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_similarity1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzTvDLVZV12a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b156eabc-c1e3-4666-a3a4-5a30f8093458"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk import TreebankWordTokenizer\n",
        "import os\n",
        "import string\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from keras import layers\n",
        "from keras.layers import merge\n",
        "from keras import Input\n",
        "from keras.models import Model, model_from_json\n",
        "from keras.optimizers import Adadelta\n",
        "from keras.callbacks import EarlyStopping\n",
        "import keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmqupDfBV5RE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "c27c997f-9f68-46d0-b2d1-d4d9e3e6c586"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "STOP_WORDS = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer() "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjY0Xl0UWMlR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "658fc545-de2e-4ce6-f1fa-78f4ca69069b"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-28 13:33:38--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-03-28 13:33:38--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-03-28 13:33:39--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  1.97MB/s    in 6m 30s  \n",
            "\n",
            "2020-03-28 13:40:09 (2.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLJoyB_EWQnQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "900e539c-7cc4-43a9-a91c-c77c6733de8c"
      },
      "source": [
        "!unzip glove*.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad0t4eXEX00i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_glove():\n",
        "  embedding = {}\n",
        "  f = open('/content/glove.6B.50d.txt',encoding='utf-8')\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coeff = np.asarray(values[1:],dtype = 'float32')\n",
        "    embedding[word] = coeff\n",
        "  f.close()\n",
        "  return embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgRZUyM1X8qK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_vector(word):\n",
        "  if word in embeddings:\n",
        "    return embeddings[word]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWchJeyYYfNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorise_sentence(sentence):\n",
        "    tokens = tokenizer.tokenize(sentence)\n",
        "    vector = []\n",
        "    for token in tokens:\n",
        "        if token not in string.punctuation:\n",
        "            token_vector = get_vector(token)\n",
        "            if token_vector is not None:\n",
        "                vector.append(token_vector)\n",
        "                \n",
        "    return vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrQlNQEdYhuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorize_df(df):\n",
        "  vectors_a = [vectorise_sentence(s) for s in df.sentence_A]\n",
        "  vectors_b = [vectorise_sentence(s) for s in df.sentence_B]\n",
        "  scores = ((df.relatedness_score-1)/4).tolist()\n",
        "  return vectors_a,vectors_b,scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne_GcokZYkmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_custom(sentence1,sentence2,max_len,model):\n",
        "  vectors_a = [vectorise_sentence(sentence1)]\n",
        "  vectors_a = pad_sequences(vectors_a,padding ='post',maxlen=max_len)\n",
        "\n",
        "  vectors_b = [vectorise_sentence(sentence2)]\n",
        "  vectors_b = pad_sequences(vectors_b,padding = 'post',maxlen=max_len)\n",
        "\n",
        "  normalized_score = model.predict([vectors_a,vectors_b])\n",
        "  return normalized_score*4 + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRSKj_02YnkR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lemmatize_word(text): \n",
        "    lemmas = [lemmatizer.lemmatize(word, pos ='v') for word in text] \n",
        "    return lemmas "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju25BfB1YpvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(lines):\n",
        "  '''Clean text by removing unnecessary characters and altering the format of words.'''\n",
        "  re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
        "  cleaned = list()\n",
        "  for text in lines:\n",
        "      text = text.lower()\n",
        "      \n",
        "      text = re.sub(r\"i'm\", \"i am\", text)\n",
        "      text = re.sub(r\"he's\", \"he is\", text)\n",
        "      text = re.sub(r\"she's\", \"she is\", text)\n",
        "      text = re.sub(r\"it's\", \"it is\", text)\n",
        "      text = re.sub(r\"that's\", \"that is\", text)\n",
        "      text = re.sub(r\"what's\", \"that is\", text)\n",
        "      text = re.sub(r\"where's\", \"where is\", text)\n",
        "      text = re.sub(r\"how's\", \"how is\", text)\n",
        "      text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "      text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "      text = re.sub(r\"\\'re\", \" are\", text)\n",
        "      text = re.sub(r\"\\'d\", \" would\", text)\n",
        "      text = re.sub(r\"\\'re\", \" are\", text)\n",
        "      text = re.sub(r\"won't\", \"will not\", text)\n",
        "      text = re.sub(r\"can't\", \"cannot\", text)\n",
        "      text = re.sub(r\"n't\", \" not\", text)\n",
        "      text = re.sub(r\"n'\", \"ng\", text)\n",
        "      text = re.sub(r\"'bout\", \"about\", text)\n",
        "      text = re.sub(r\"'til\", \"until\", text)\n",
        "      text = re.sub(r\"[$-()\\\"#/@;:<>{}`+=~|.!?,'*-]\", \"\", text)\n",
        "                        \n",
        "      text = text.split()\n",
        "      text = [re_print.sub('', w) for w in text]\n",
        "      text = [token for token in text if token not in STOP_WORDS]\n",
        "      text = lemmatize_word(text)\n",
        "      cleaned.append(' '.join(text))\n",
        "                        \n",
        "  return cleaned"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prU9kZ7KYr24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings = load_glove()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4q_Yhb4Yt4H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "7e7ed2b9-4935-4298-ebb4-a3f466c7f9e0"
      },
      "source": [
        "\n",
        "!pip install wget\n",
        "import wget\n",
        "url = 'https://raw.githubusercontent.com/jaydeepthik/Siamese-Sentence-Similarity/master/SICK/SICK.txt'\n",
        "wget.download(url,'SICK.txt')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=142698fb384fb2365248f1de0843e96863b1aeec83ae2f5576d9cd59c180d785\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SICK.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6yZ4ylgYwMf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = TreebankWordTokenizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kl-gYzvkYy0P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath='/content/SICK.txt'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qAEhqpfY05J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(filepath, sep='\\t')[['sentence_A', 'sentence_B', 'relatedness_score', 'SemEval_set']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLhjZcwKY3Lo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "b16b86d4-3879-471a-a194-0934e77d9c7c"
      },
      "source": [
        "\n",
        "df.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_A</th>\n",
              "      <th>sentence_B</th>\n",
              "      <th>relatedness_score</th>\n",
              "      <th>SemEval_set</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A group of kids is playing in a yard and an ol...</td>\n",
              "      <td>A group of boys in a yard is playing and a man...</td>\n",
              "      <td>4.5</td>\n",
              "      <td>TRAIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A group of children is playing in the house an...</td>\n",
              "      <td>A group of kids is playing in a yard and an ol...</td>\n",
              "      <td>3.2</td>\n",
              "      <td>TRAIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The young boys are playing outdoors and the ma...</td>\n",
              "      <td>The kids are playing outdoors near a man with ...</td>\n",
              "      <td>4.7</td>\n",
              "      <td>TRAIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The young boys are playing outdoors and the ma...</td>\n",
              "      <td>There is no boy playing outdoors and there is ...</td>\n",
              "      <td>3.6</td>\n",
              "      <td>TRIAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The kids are playing outdoors near a man with ...</td>\n",
              "      <td>A group of kids is playing in a yard and an ol...</td>\n",
              "      <td>3.4</td>\n",
              "      <td>TRAIN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          sentence_A  ... SemEval_set\n",
              "0  A group of kids is playing in a yard and an ol...  ...       TRAIN\n",
              "1  A group of children is playing in the house an...  ...       TRAIN\n",
              "2  The young boys are playing outdoors and the ma...  ...       TRAIN\n",
              "3  The young boys are playing outdoors and the ma...  ...       TRIAL\n",
              "4  The kids are playing outdoors near a man with ...  ...       TRAIN\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnAjBQ3WY5NC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = df[df['SemEval_set'] == 'TRAIN']\n",
        "dev_data = df[df['SemEval_set']=='TRIAL']\n",
        "test_data = df[df['SemEval_set']=='TEST']\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qppys4VTY7IK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "ede2cd4d-a2c7-4207-ad45-954eaa5b09fc"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_A</th>\n",
              "      <th>sentence_B</th>\n",
              "      <th>relatedness_score</th>\n",
              "      <th>SemEval_set</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A group of kids is playing in a yard and an ol...</td>\n",
              "      <td>A group of boys in a yard is playing and a man...</td>\n",
              "      <td>4.5</td>\n",
              "      <td>TRAIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A group of children is playing in the house an...</td>\n",
              "      <td>A group of kids is playing in a yard and an ol...</td>\n",
              "      <td>3.2</td>\n",
              "      <td>TRAIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The young boys are playing outdoors and the ma...</td>\n",
              "      <td>The kids are playing outdoors near a man with ...</td>\n",
              "      <td>4.7</td>\n",
              "      <td>TRAIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The kids are playing outdoors near a man with ...</td>\n",
              "      <td>A group of kids is playing in a yard and an ol...</td>\n",
              "      <td>3.4</td>\n",
              "      <td>TRAIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>The young boys are playing outdoors and the ma...</td>\n",
              "      <td>A group of kids is playing in a yard and an ol...</td>\n",
              "      <td>3.7</td>\n",
              "      <td>TRAIN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          sentence_A  ... SemEval_set\n",
              "0  A group of kids is playing in a yard and an ol...  ...       TRAIN\n",
              "1  A group of children is playing in the house an...  ...       TRAIN\n",
              "2  The young boys are playing outdoors and the ma...  ...       TRAIN\n",
              "4  The kids are playing outdoors near a man with ...  ...       TRAIN\n",
              "8  The young boys are playing outdoors and the ma...  ...       TRAIN\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Kz6ubNCY9cp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['sentence_A'] = clean_text(df['sentence_A'])\n",
        "df['sentence_B'] = clean_text(df['sentence_B'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXi8FvzpaT-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_A = train_data['sentence_A'].tolist()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeYnsl-kao9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_B = train_data['sentence_B'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maHd_q6bbApB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_scores(df):\n",
        "  scores = ((df.relatedness_score-1)/4).tolist()\n",
        "  return scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "najslDdabPnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores = get_scores(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXb7CJYsbW-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ncj6HpTbk3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentence_A + sentence_B)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txT7C4plbx2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "se_a = tokenizer.texts_to_sequences(sentence_A)\n",
        "se_b = tokenizer.texts_to_sequences(sentence_B)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPSXRc2PcALT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_a = max(len(s) for s in se_a)\n",
        "max_b = max(len(s) for s in se_b)\n",
        "max_len = max([max_a,max_b])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QrOUEzfcOmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_a = pad_sequences(se_a,maxlen=max_len,padding='post',truncating='post')\n",
        "train_b = pad_sequences(se_b,maxlen=max_len, padding = 'post',truncating='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq_yKDc7kd4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def create_train_dev_set(sentence_A,sentence_B, max_sequence_length,scores,validation_split_ratio):\n",
        "    \"\"\"\n",
        "    Create training and validation dataset\n",
        "    Args:\n",
        "        tokenizer (keras.preprocessing.text.Tokenizer): keras tokenizer object\n",
        "        sentences_pair (list): list of tuple of sentences pairs\n",
        "        is_similar (list): list containing labels if respective sentences in sentence1 and sentence2\n",
        "                           are same or not (1 if same else 0)\n",
        "        max_sequence_length (int): max sequence length of sentences to apply padding\n",
        "        validation_split_ratio (float): contain ratio to split training data into validation data\n",
        "    Returns:\n",
        "        train_data_1 (list): list of input features for training set from sentences1\n",
        "        train_data_2 (list): list of input features for training set from sentences2\n",
        "        labels_train (np.array): array containing similarity score for training data\n",
        "        leaks_train(np.array): array of training leaks features\n",
        "        val_data_1 (list): list of input features for validation set from sentences1\n",
        "        val_data_2 (list): list of input features for validation set from sentences1\n",
        "        labels_val (np.array): array containing similarity score for validation data\n",
        "        leaks_val (np.array): array of validation leaks features\n",
        "    \"\"\"\n",
        "    #sentences1 = [x[0].lower() for x in sentences_pair]\n",
        "    #sentences2 = [x[1].lower() for x in sentences_pair]\n",
        "    #train_sequences_1 = tokenizer.texts_to_sequences(sentences1)\n",
        "    #train_sequences_2 = tokenizer.texts_to_sequences(sentences2)\n",
        "    leaks = [[len(set(x1)), len(set(x2)), len(set(x1).intersection(x2))]\n",
        "             for x1, x2 in zip(se_a,se_b)]\n",
        "\n",
        "    #train_padded_data_1 = pad_sequences(train_sequences_1, maxlen=max_sequence_length)\n",
        "    #train_padded_data_2 = pad_sequences(train_sequences_2, maxlen=max_sequence_length)\n",
        "    train_labels = np.array(scores)\n",
        "    leaks = np.array(leaks)\n",
        "\n",
        "    shuffle_indices = np.random.permutation(np.arange(len(train_labels)))\n",
        "    train_data_1_shuffled = train_a[shuffle_indices]\n",
        "    train_data_2_shuffled = train_b[shuffle_indices]\n",
        "    train_labels_shuffled = train_labels[shuffle_indices]\n",
        "    leaks_shuffled = leaks[shuffle_indices]\n",
        "\n",
        "    dev_idx = max(1, int(len(train_labels_shuffled) * validation_split_ratio))\n",
        "\n",
        "    #del train_padded_data_1\n",
        "    #del train_padded_data_2\n",
        "    #gc.collect()\n",
        "\n",
        "    train_data_1, val_data_1 = train_data_1_shuffled[:-dev_idx], train_data_1_shuffled[-dev_idx:]\n",
        "    train_data_2, val_data_2 = train_data_2_shuffled[:-dev_idx], train_data_2_shuffled[-dev_idx:]\n",
        "    labels_train, labels_val = train_labels_shuffled[:-dev_idx], train_labels_shuffled[-dev_idx:]\n",
        "    leaks_train, leaks_val = leaks_shuffled[:-dev_idx], leaks_shuffled[-dev_idx:]\n",
        "\n",
        "    return train_data_1, train_data_2, labels_train, leaks_train, val_data_1, val_data_2, labels_val, leaks_val\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0inNRcRmy73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_x1, train_data_x2, train_labels, leaks_train,val_data_x1, val_data_x2, val_labels, leaks_val = create_train_dev_set(sentence_A,sentence_B, max_len,scores,validation_split_ratio =0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU0fcXjAc11L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size=len(tokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EiwjZiydA7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_words_input=len(tokenizer.word_index)+1\n",
        "word2idx_input=tokenizer.word_index\n",
        "\n",
        "num_words=num_words_input\n",
        "embedding_matrix=np.zeros((num_words,50))\n",
        "for word,i in word2idx_input.items():\n",
        "    if i<num_words_input:\n",
        "        embedding_vector=embeddings.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i]=embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31fPCDN-dgD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "embed_layer = tf.keras.layers.Embedding(vocab_size,50,weights = [embedding_matrix],input_length = max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bywyOyuQduMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LSTM = tf.keras.layers.LSTM(50, unit_forget_bias=True, kernel_initializer='he_normal', kernel_regularizer='l2', name='lstm_layer')\n",
        "left_input = tf.keras.layers.Input(shape=(max_len,))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_QNMW6lec2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "left_input_1 = embed_layer(left_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mfi6Cr7ffKcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "left_output = LSTM(left_input_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUXnhmNqfSX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "right_input = tf.keras.layers.Input(shape=(max_len,))\n",
        "right_input_1 = embed_layer(right_input)\n",
        "right_output = LSTM(right_input_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYY_uJzEfTOX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.keras.backend as K\n",
        "def exponent_neg_manhattan_distance(x, hidden_size=50):\n",
        "    ''' Helper function for the similarity estimate of the LSTMs outputs '''\n",
        "    return K.exp(-K.sum(K.abs(x[:,:hidden_size] - x[:,hidden_size:]), axis=1, keepdims=True))\n",
        "\n",
        "def exponent_neg_cosine_distance(x, hidden_size=50):\n",
        "    ''' Helper function for the similarity estimate of the LSTMs outputs '''\n",
        "    leftNorm = K.l2_normalize(x[:,:hidden_size], axis=-1)\n",
        "    rightNorm = K.l2_normalize(x[:,hidden_size:], axis=-1)\n",
        "    return K.exp(K.sum(K.prod([leftNorm, rightNorm], axis=0), axis=1, keepdims=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtK1s_QbfTLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "concats = tf.keras.layers.concatenate([left_output,right_output],axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxuTCKg_gUqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "main_output = tf.keras.layers.Lambda(exponent_neg_manhattan_distance, output_shape=(1,))(concats)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSNqBShRgUBf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Model([left_input, right_input],concats)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J90wuK67hT_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='mean_squared_error', metrics=['mae','mse'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-vxkqO6nzxi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "c10c400b-8a64-40bd-d5ad-a4fc76e823d2"
      },
      "source": [
        " model.fit([train_data_x1, train_data_x2, leaks_train], train_labels,\n",
        "                  validation_data=([val_data_x1, val_data_x2, leaks_val], val_labels),\n",
        "                  epochs=50, batch_size=32)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " 85/111 [=====================>........] - ETA: 1s - loss: 0.0642 - mae: 0.1973 - mse: 0.0642"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-124-9fa7e3ac28f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit([train_data_x1, train_data_x2, leaks_train], train_labels,\n\u001b[1;32m      2\u001b[0m                  \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_data_x1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data_x2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleaks_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                  epochs=50, batch_size=32)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    781\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    782\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djVl3lSxvqOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.save('model.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwgezZOovvMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_1 = ['What can make Physics easy to learn?']\n",
        "sentence_2=['How can you make physics easy to learn?']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RAfQpF3wGod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_1=clean_text(sentence_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vRdd3NFwHAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_2=clean_text(sentence_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_Po3p4fw1WF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_1=tokenizer.texts_to_sequences(sentence_1)\n",
        "sentence_2 = tokenizer.texts_to_sequences(sentence_2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VUtfCCVxHWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence1 = pad_sequences(sentence_1,padding='post',maxlen = max_len)\n",
        "sentence2 = pad_sequences(sentence_2,padding='post',maxlen = max_len)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTotqVA4wyuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_test_data(tokenizer, sentence1,sentence2, max_sequence_length):\n",
        "    \"\"\"\n",
        "    Create training and validation dataset\n",
        "    Args:\n",
        "        tokenizer (keras.preprocessing.text.Tokenizer): keras tokenizer object\n",
        "        test_sentences_pair (list): list of tuple of sentences pairs\n",
        "        max_sequence_length (int): max sequence length of sentences to apply padding\n",
        "    Returns:\n",
        "        test_data_1 (list): list of input features for training set from sentences1\n",
        "        test_data_2 (list): list of input features for training set from sentences2\n",
        "    \"\"\"\n",
        "    #test_sentences1 = [x[0].lower() for x in test_sentences_pair]\n",
        "    #test_sentences2 = [x[1].lower() for x in test_sentences_pair]\n",
        "\n",
        "    #test_sequences_1 = tokenizer.texts_to_sequences(test_sentences1)\n",
        "    #test_sequences_2 = tokenizer.texts_to_sequences(test_sentences2)\n",
        "    leaks_test = [[len(set(x1)), len(set(x2)), len(set(x1).intersection(x2))]\n",
        "                  for x1, x2 in zip(sentence_1,sentence_2)]\n",
        "\n",
        "    leaks_test = np.array(leaks_test)\n",
        "    #test_data_1 = pad_sequences(test_sequences_1, maxlen=max_sequence_length)\n",
        "    #test_data_2 = pad_sequences(test_sequences_2, maxlen=max_sequence_length)\n",
        "\n",
        "    return sentence1,sentence2, leaks_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60Zw9E-twytC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence1,sentence2, leaks_test = create_test_data(tokenizer, sentence1,sentence2, max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAeFDe3dwyrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aJCsoqYwyTS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44855a82-8ca7-4e86-c915-c496acf5c3ec"
      },
      "source": [
        "model = load_model('model.h5')\n"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCO7749bysLb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fdb19c5a-f04f-48ea-fbb3-aea362adbba2"
      },
      "source": [
        "preds = list(model.predict([sentence1,sentence2, leaks_test], verbose=1).ravel())"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYFiYHCgzCwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sentence_pairs = [('What can make Physics easy to learn?','How can you make physics easy to learn?')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDJi14dIy2iI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = [(x, y, z) for (x, y), z in zip(test_sentence_pairs, preds)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpOjRaH0zNuD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93cc44a6-dbb0-42d2-84c6-ce3cf48a0c2b"
      },
      "source": [
        "from operator import itemgetter\n",
        "results.sort(key=itemgetter(2), reverse=True)\n",
        "print(results)\n"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('What can make Physics easy to learn?', 'How can you make physics easy to learn?', 0.6220899)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxwsiwpezNBS",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}